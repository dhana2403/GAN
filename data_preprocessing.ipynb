{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def preprocess_metadata(file_path):\n",
    "     \"\"\"\n",
    "    Load attribute and phenotype files and clean them\n",
    "    \"\"\"\n",
    "\n",
    "     if \"Attributes\" in file_path:\n",
    "         att_val = (\n",
    "           pd.read_csv(file_path, sep='\\t')\n",
    "           .fillna(\"\")\n",
    "           .rename(columns={'SAMPID':'samp_id','SMRIN':'rin_val', 'SMTS': 'major_tissue', 'SMTSD': 'minor_tissue', 'SMNABTCH':'batch_iso', 'SMGEBTCH':'batch_exp', 'SMTSISCH': 'ischemic_time'})\n",
    "           .assign(minor_tissue = lambda df: df['minor_tissue'].str.replace(' - ', '-', regex=False),\n",
    "                   subj_id = lambda df: df['samp_id'].str.split('-', n=2).str[:2].apply('-'.join)))\n",
    "         return att_val[['samp_id', 'subj_id', 'rin_val', 'major_tissue', 'minor_tissue', 'batch_iso', 'batch_exp', 'ischemic_time']]\n",
    "\n",
    "     elif \"Phenotypes\" in file_path:\n",
    "          \n",
    "         phe_val = (\n",
    "            pd.read_csv(file_path, sep='\\t')\n",
    "            .fillna(\"\")\n",
    "            .rename(columns={'SUBJID': 'subj_id', 'SEX': 'sex', 'AGE': 'age', 'DTHHRDY': 'Death_category'})\n",
    "            .assign(sex = lambda df : df['sex'].replace({1:\"male\", 2:\"female\"}), \n",
    "                    Death_category = lambda df: df['Death_category'].replace({0: \"Ventilator\", 1: \"Fast & violent\", 2: \"Fast & natural\", 3: \"Intermediate\", 4: \"slow death\"}))\n",
    "                )\n",
    "         return phe_val[['subj_id', 'sex', 'age', 'Death_category']]\n",
    "    \n",
    "     else:\n",
    "         raise ValueError(\"File path must contain 'Attributes' or 'Phenotypes' to be recognized.\")\n",
    "    \n",
    "\n",
    "def load_and_filter_expression (rawfile_path, sample_ids, genes_of_interest):\n",
    "    \n",
    "    \"\"\"\n",
    "    Load raw gene expression data, filter by sample IDs and genes of interest.\n",
    "    \"\"\"\n",
    "    columns_to_keep = ['Name']+[col for col in sample_ids if col in pd.read_csv(rawfile_path, sep='\\t', skiprows=2, nrows=0).columns]\n",
    "\n",
    "    raw_dat = pd.read_csv(rawfile_path, sep='\\t', skiprows=2, header=0, usecols=columns_to_keep)\n",
    "    raw_dat['Name'] = raw_dat['Name'].str.replace(r\"(\\.\\d+)$\", \"\", regex=True)\n",
    "    raw_dat = raw_dat[raw_dat['Name'].isin(genes_of_interest)].set_index('Name')\n",
    "\n",
    "    return raw_dat\n",
    "\n",
    "def group_sample_by_tissues(metadata_df, raw_dat):\n",
    "    \"\"\"\n",
    "    Group samples by tissue and filter raw expression data accordingly.\n",
    "    Returns a dict of {tissue: DataFrame of expression data}.\n",
    "    \"\"\"\n",
    "    sample_meta = metadata_df.groupby(\"minor_tissue\")[\"samp_id\"].apply(list).to_dict()\n",
    "    sample_raw = set(raw_dat.columns)\n",
    "\n",
    "    # Filter samples in raw data for each tissue\n",
    "    sample_meta = {tissue: list(set(samples) & sample_raw) for tissue, samples in sample_meta.items()}\n",
    "\n",
    "    # Keep tissues with at least 2 samples\n",
    "    dat_filtered_tissues = {\n",
    "         tissue: raw_dat[samples].dropna(axis=1)\n",
    "         for tissue, samples in sample_meta.items()\n",
    "         if len(samples)>1\n",
    "     }\n",
    "\n",
    "    dat_filtered_tissues = { \n",
    "        tissue: df.rename(columns= lambda x: re.split(r'[()]', x.replace('', ''))[0])\n",
    "        for tissue, df in dat_filtered_tissues.items()  \n",
    "    }\n",
    "\n",
    "    return dat_filtered_tissues\n",
    "\n",
    "def save_dataframes(dataframes_dict, save_dir):\n",
    "   \"\"\"\n",
    "    Save expression data dict as pickles; optionally save metadata.\n",
    "    \"\"\"\n",
    "   os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "   for tissue, df in dataframes_dict.items():\n",
    "      pickle.dump(df, open(os.path.join(save_dir, f\"{tissue}.pkl\"), \"wb\"))\n",
    "\n",
    "def main(att_path, phe_path, raw_path):\n",
    "   \"\"\"\n",
    "    preprocess attributes, phenotype and raw data files\n",
    "    \"\"\"\n",
    "   print(\"hi\")\n",
    "\n",
    "   att_val_new = preprocess_metadata(att_path)\n",
    "   phe_val = preprocess_metadata(phe_path)\n",
    "\n",
    "   attphe = (\n",
    "      att_val_new\n",
    "      .merge(phe_val, on='subj_id', how='inner')\n",
    "      .drop_duplicates(subset='samp_id', keep='first')\n",
    "   )\n",
    "   attphe = attphe[attphe['minor_tissue'] == 'Brain-Cortex']\n",
    "   samp_ids = attphe['samp_id'].to_list()\n",
    "\n",
    "   genes_of_interest = [\n",
    "      'ENSG00000198793', 'ENSG00000118689', 'ENSG00000096717', 'ENSG00000142082',\n",
    "      'ENSG00000133818', 'ENSG00000121691', 'ENSG00000017427', 'ENSG00000140443',\n",
    "      'ENSG00000141510', 'ENSG00000077463', 'ENSG00000130203', 'ENSG00000126458',\n",
    "      'ENSG00000142168', 'ENSG00000133116']\n",
    "    \n",
    "   raw_dat = load_and_filter_expression(raw_path, samp_ids, genes_of_interest)\n",
    "\n",
    "   dat_filtered_tissues = group_sample_by_tissues(attphe, raw_dat)\n",
    "\n",
    "   save_dir = \"data/processed/expression/readcounts_all/\"\n",
    "   metadata_path = \"data/processed/attphe.pkl\"\n",
    "   save_dataframes(dat_filtered_tissues, save_dir, metadata_df = attphe, metadata_path= metadata_path)\n",
    "\n",
    "   print(f\"Processed data saved to:\\n- {save_dir}\\n- {metadata_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r-tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
